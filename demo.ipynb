{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from genetic_programming.genetics import SymbolicRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import  Ridge\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('./data/70_dataset.csv')\n",
    "x.set_index('compound', inplace=True)\n",
    "x = x.drop(x.columns[x.nunique() == 1], axis=1)\n",
    "y = x.pop('target')\n",
    "x = x\n",
    "feature_name = x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(X_list):\n",
    "    x = X_list[0]\n",
    "    for i in range(len(X_list)-1):\n",
    "        x = np.c_[x, X_list[i+1]]\n",
    "    return x\n",
    "\n",
    "def LR(x_tr, x_ts, y_tr, y_ts, alpha, dimension):\n",
    "    ols = Ridge(alpha=alpha)\n",
    "    model = ols.fit(x_tr, y_tr)\n",
    "    pred_tr = model.predict(x_tr)\n",
    "    pred_ts = model.predict(x_ts)\n",
    "\n",
    "    tr_result = r2_score(y_tr, pred_tr)\n",
    "    ts_result = r2_score(y_ts, pred_ts)\n",
    "\n",
    "    return pred_tr, pred_ts, tr_result, ts_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Dimension - inv(div(BEtmx, Rtm))\n",
      "1 Dimension - Training : 0.40293383731005594 | Test : 0.6880644463221829\n",
      "2 Dimension - inv(sub(DVEtm, Vtmx))\n",
      "2 Dimension - Training : 0.5739180184004931 | Test : 0.7412927065069477\n",
      "3 Dimension - add(Nxs, Vtm)\n",
      "3 Dimension - Training : 0.6567109889904947 | Test : 0.7201962538300211\n",
      "4 Dimension - log(DVEtm)\n",
      "4 Dimension - Training : 0.6569751749283519 | Test : 0.6991531489311533\n",
      "5 Dimension - pow2(sub(Wx, Wtm))\n",
      "5 Dimension - Training : 0.6852712858857054 | Test : 0.7181720471970856\n",
      "6 Dimension - Qtm\n",
      "6 Dimension - Training : 0.6917103954984354 | Test : 0.7250837270135865\n",
      "7 Dimension - inv(log(sub(Qtm, Vtmx)))\n",
      "7 Dimension - Training : 0.7443748743410221 | Test : 0.7367170943685689\n",
      "8 Dimension - Ctm\n",
      "8 Dimension - Training : 0.753078787039407 | Test : 0.7342095015442306\n",
      "9 Dimension - sqrt(sqrt(sqrt(log(sub(Nxs, Vtmx)))))\n",
      "9 Dimension - Training : 0.7837341798702921 | Test : 0.7292474913848324\n",
      "10 Dimension - div(LEf, Ctm)\n",
      "10 Dimension - Training : 0.787523947828434 | Test : 0.7198481291488754\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=389)\n",
    "\n",
    "list_of_iter_result = []\n",
    "list_of_iter_data = []\n",
    "\n",
    "x_tr_data, x_ts_data, y_tr_data, y_ts_data = [x_tr], [x_ts], [y_tr], [y_ts]\n",
    "\n",
    "for d in range(10):\n",
    "    ## You can change hyperparameters in here (population, generation, etc)\n",
    "    gp = SymbolicRegressor(population_size=7000, generations=15, init_depth=(1, 2), metric='pearson',\n",
    "                            feature_names=feature_name, parsimony_coefficient=0.03,\n",
    "                            tournament_size=100, stopping_criteria=0.8, low_memory=True, n_jobs=16,random_state=1)\n",
    "\n",
    "\n",
    "    gp.fit(x_tr_data[0], y_tr_data[-1])\n",
    "\n",
    "    x_tr_descriptor = gp.predict(x_tr_data[0]).reshape(-1, 1)\n",
    "    x_ts_descriptor = gp.predict(x_ts_data[0]).reshape(-1, 1)\n",
    "\n",
    "    \n",
    "\n",
    "    x_tr_data.append(x_tr_descriptor)\n",
    "    x_ts_data.append(x_ts_descriptor)\n",
    "    \n",
    "\n",
    "    program = str(gp._program)\n",
    "\n",
    "    X_tr, X_ts = x_tr_data[1:], x_ts_data[1:]\n",
    "\n",
    "    X_tr = assign(X_tr)\n",
    "    X_ts = assign(X_ts)\n",
    "\n",
    "    pred_tr, pred_ts, tr_result, ts_result = LR(X_tr, X_ts, y_tr_data[0], y_ts_data[0], 1, d + 1)\n",
    "    res_tr, res_ts = y_tr_data[0] - pred_tr, y_ts_data[0] - pred_ts\n",
    "    y_tr_data.append(res_tr)\n",
    "    y_ts_data.append(res_ts)\n",
    "    print(f'{d+1} Dimension - {program}')\n",
    "    print(f'{d+1} Dimension - Training : {tr_result} | Test : {ts_result}')\n",
    "\n",
    "list_of_data = [x_tr_data, x_ts_data, y_tr_data, y_ts_data]\n",
    "\n",
    "list_of_iter_data.append(list_of_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf0eb061f6db49036dd9042a11eed065a84f4c36216f2f89e069dfd173229e78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
